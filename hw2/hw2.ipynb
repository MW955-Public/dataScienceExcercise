{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 2950 Homework 2\n",
    "# Part 1: `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "narrative": true
   },
   "source": [
    "The following cell installs two Python packages useful for web scraping. (If you already have them installed, the code will produce a message that \"Requirement already satisfied\".) **If either is installed now, you may need to close Jupyter and restart it in order to use the libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "narrative": true
   },
   "outputs": [],
   "source": [
    "# install requests and beautiful soup \n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} requests\n",
    "!conda install --yes --prefix {sys.prefix} bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "narrative": true
   },
   "outputs": [],
   "source": [
    "import requests #package for http requests\n",
    "import bs4 # package for html parsing\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "narrative": true
   },
   "source": [
    "## Reminder:\n",
    "Do not move or modify **Problem #** cells. Our grading script extracts the cells between these header cells to split grading across our TAs. If needed, you may add more cells between these header cells for coding or explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 1
   },
   "source": [
    "---\n",
    "#### Problem 1 (4 pts)\n",
    "Use a `numpy` function similar to Python's `range()` function to create a numpy array of integers from 0-8. Then use the `numpy.reshape()` command to change the array's shape to 3 rows and 3 columns. The numbers should increment row-wise within the array. Print the final result.\n",
    "\n",
    "*(**Hint:** the `numpy` equivalent to Python's `range()` function can be found in the [quickstart tutorial](https://numpy.org/doc/stable/user/quickstart.html).)*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 2
   },
   "source": [
    "---\n",
    "\n",
    "#### Problem 2 (2 pts)\n",
    "Beyond integers, `numpy` can generate a list of evenly spaced values within a specified interval using `numpy.linspace()`. Use this function to create the array `[0, 0.25, 0.5, 0.75, 1]`. Print the final result.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 3
   },
   "source": [
    "---\n",
    "\n",
    "#### Problem 3 (4 pts)\n",
    "`numpy.zeros()` is a function to instantiate an numpy array of zeros. Use this function to create a new array of zeros with 5 rows and 5 columns and an integer datatype. Then use a nested for loop to iterate over the row and column indices, filling the entries row-wise with the integers from 1 to 25.\n",
    "\n",
    "Print the final array, as well as the data type of the first entry in the array (using the `numpy.dtype` function).\n",
    "\n",
    "_**Confidence check:** the final array should look like this:_\n",
    "```\n",
    "array([[ 1,  2,  3,  4,  5],\n",
    "       [ 6,  7,  8,  9, 10],\n",
    "       [11, 12, 13, 14, 15],\n",
    "       [16, 17, 18, 19, 20],\n",
    "       [21, 22, 23, 24, 25]])\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "narrative": true
   },
   "source": [
    "---\n",
    "# Part 2: Exploratory data analysis\n",
    "\n",
    "Our overarching goal in this course is to **explain variation** observed in data, which may be complex with many observations *(rows)* and variables *(columns)*. Explaining variation involves finding the most plausible process(es) *(properties of and relationships between columns)* that generated the observations *(rows)*. \n",
    "\n",
    "We start by poking, proding, and visualizing the data in various ways to uncover patterns and figure out what kinds of formal analyses may be interesting and appropriate. This first step is often referred to as **exploratory data analysis** (EDA).\n",
    "\n",
    "As with data cleaning, there is no singular way to perform EDA. It really depends on the data you have on hand, as well as the domain-specific context from which the data came. \n",
    "\n",
    "Here are some guides for EDA (which may come in especially handy for phase 2 of the final project):\n",
    "* [a brief overview of the ideas/philosophy behind EDA](https://www.itl.nist.gov/div898/handbook/eda/section1/eda11.htm)\n",
    "* [a medium-depth dive into EDA with examples](https://r4ds.had.co.nz/exploratory-data-analysis.html) (note that the code is in R, though there are readily-available analogues in `pandas`)\n",
    "* [a thorough guide of EDA](http://www.stat.cmu.edu/~hseltman/309/Book/chapter4.pdf)\n",
    "\n",
    "Here are some tools at your disposal when performing exploratory data analysis:\n",
    "* _summary statistics:_ mean, median, mode, standard deviation, variance, quantiles\n",
    "* _plots:_ histograms, boxplots, scatterplots\n",
    "\n",
    "---\n",
    "\n",
    "In the following set of exercises, we're we'll explore variance in book prices.\n",
    "\n",
    "Histograms are a good first step in exploratory data analysis as they only involve information about *one variable*. Before moving on to modelling the relationship between two or more variables, it's good to know more about each individual variable.\n",
    "\n",
    "We can easily make histograms in Python using the function `hist()` from the submodule `matplotlib.pyplot` (here's the [documentation](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html), as well [a nice overview](https://jakevdp.github.io/PythonDataScienceHandbook/04.05-histograms-and-binnings.html) about how to create histograms in Python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 4
   },
   "source": [
    "---\n",
    "\n",
    "#### Problem 4 (5 pts)\n",
    "\n",
    "Import the submodule `matplotlib.pyplot` as `plt`. Load the file `books.csv` as a `pandas DataFrame` called `books`. Plot a histogram for the `price` column using `plt.hist()`. Label the $x-$ and $y-$axes with \"price\" and \"count\", respectively. Explain why the histogram is not useful.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 5
   },
   "source": [
    "---\n",
    "\n",
    "#### Problem 5 (3 pts)\n",
    "Update the `books` dataframe to exclude the observation with the largest book price and re-make the histogram from problem 4 with the updated dataframe. \n",
    "\n",
    "**Note:** all subsequent problems should use the updated `books` data frame, which excludes the row corresponding to the largest book price in the original data.\n",
    "\n",
    "This distribution has two peaks: one around fifteen dollars and one around twenty-seven. Explain: why might this distribution might have two peaks...? (See [here](https://www.slj.com/?detailStory=sljs-average-book-prices-2018) for a hint.) Knowing that the distribution of book prices has two peaks (and having an idea of what might drive this pattern) could affect modelling choices we make down the line.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "narrative": true
   },
   "source": [
    "---\n",
    "A small group of observations that are significantly far from the bulk of the data are called **outliers**. Outliers may be interesting points to investigate further, or they may result from data entry errors. In this case, notice that the maximum book price in the original data set is about 100x larger than the rest of the prices. This likely resulted from this price being entered without a decimal point, and so is probably a simple data entry error.\n",
    "\n",
    "Histograms are one way to detect outliers. In general, histograms can allow us to **detect biases** within single variables of our data. We can usually correct for biases, but only if we know about them! Consider experimenting with the `range` and `bin` parameters within the `hist()` function (ex: hist(bins=100)) to familiarize yourself with different ways of visualizing data and accounting for outliers.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 6
   },
   "source": [
    "---\n",
    "\n",
    "#### Problem 6 (5 pts)\n",
    "What is the highest price for each genre in the updated `books` dataframe (with the outlier price removed)? Loop over the genres and print the genre name, followed by the max price within the genre. \n",
    "\n",
    "**When printing numbers throughout this notebook, please round to two decimal places and provide context for the number.** \n",
    "\n",
    "*In this case, label the number with its genre and \"max price: \"*\n",
    "\n",
    "*Hint: You may find it useful to [subset your dataframe](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#the-where-method-and-masking) for each genre and the use the `.max()` on the price column.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 7
   },
   "source": [
    "---\n",
    "\n",
    "#### Problem 7 (4 pts)\n",
    "Create a histogram of the number of books published ($y-$axis) per year ($x-$axis). Be sure to clearly label each axis and give the chart an appropriate title. \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 8
   },
   "source": [
    "---\n",
    "#### Problem 8 (2 pts)\n",
    "\n",
    "Calculate the variance and standard deviation of the book's prices and print the results. \n",
    "\n",
    "**Be sure to round to two decimal places and print a description for context (similar to problem 6). Continue to do so throughout the notebook for each number you print.**\n",
    "\n",
    "*(**Hint:** A pandas column is usually accessed as a `pandas.Series` (a one-dimensional array). These arrays have methods to calculate summary statistics, like the mean, median, variance, and standard deviation.)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 9
   },
   "source": [
    "---\n",
    "\n",
    "#### Problem 9 (2 pts)\n",
    "Multiply all book prices by 3 and then calculate the variance and standard deviation of the scaled data and print the results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 10
   },
   "source": [
    "---\n",
    "\n",
    "#### Problem 10 (3 pts)\n",
    "Divide the variance in problem 9 by the variance in problem 8 and print the result. Divide the standard deviation in problem 9 by the standard deviation in problem 8 and also print this result. Briefly explain how scaling the data by a factor of three changed the variance and standard deviation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 11
   },
   "source": [
    "---\n",
    "\n",
    "#### Problem 11 (6 pts)\n",
    "\n",
    "\n",
    "A [box plot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.boxplot.html) depicts the distribution of a numerical variable based on different categorical groups. The box edges are defined by the first and third quartiles of the data, with a line at the median (the second quartile). The whiskers extend from the edges of box to show the range of (most of) the data. Some boxplot methods use the whiskers to show the *entire* range of the data, while others go to some multiple of the standard deviation (usually 1.5$\\sigma$ or 2$\\sigma$) and represent data beyond that (outliers) by single points.\n",
    "\n",
    "Use `pandas` to create a box plot of our price data grouped by genre. Which genre has the largest price range? Which has the largest median?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 12
   },
   "source": [
    "---\n",
    "\n",
    "#### Problem 12 (3 pts)\n",
    "Calculate the mean and standard deviation of the price of all books published since 2000 (inclusive).\n",
    "\n",
    "**Remember to print the values rounded to two decimal places and with prefix labels.** For instance, just printing \"2.51\" doesn't tell the reader what the value is, but \"mean: 2.51\" is properly labelled.\n",
    "\n",
    "*(**Hint:** you may find the the `pandas` `DataFrame` method [`.describe()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) useful.)*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 13
   },
   "source": [
    "---\n",
    "\n",
    "#### Problem 13 (4 pts)\n",
    "Use the `pandas` `DataFrame` `.group_by()` method to group the data by genre and calculate the mean price for each group.\n",
    "\n",
    "**Print your values rounded to two decimal places and with prefix labels.**\n",
    "\n",
    "*(**Hint:** `pandas` `DataFrame` objects have a `.mean()` method.)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 14
   },
   "source": [
    "---\n",
    "\n",
    "## Part 3: From web scraping to web crawling\n",
    "\n",
    "#### Problem 14 (4 pts)\n",
    "The web scraping example from discussion section using the `requests` and`BeautifulSoup` packages demonstrated how to extract paragraphs from a Wikipedia page. What if we were interested in all the content related to that topic, which may span several articles, stored on different web pages? Wikipedia conveniently includes hyperlinks to other Wikipedia pages for related content within the body of an article's web page.\n",
    "\n",
    "For this problem, use `requests` and`BeautifulSoup` to extract a list of all the anchor (`<a>`) tags within the text body of the [Web Scraping](https://en.wikipedia.org/wiki/Web_scraping) page. These anchor tags define a hyperlink and contain an `href` attribute, which contains the hyperlink's destination. Print the resulting list of `<a>` tags, from start to finish (including the end tag `</a>`).\n",
    "\n",
    "_(**Hint:** the provided example already demonstrates how to find all the HTML `<p>` tags. Within those paragraphs is another element to identify hyperlinks, the `<a>` tag, which can be found using the `.findAll()` method for `BeautifulSoup` objects.)_\n",
    "\n",
    "**Confidence check:** the final list should contain the first ten elements:\n",
    "```\n",
    "[<a href=\"/wiki/Data_scraping\" title=\"Data scraping\">data scraping</a>,\n",
    " <a href=\"/wiki/Data_extraction\" title=\"Data extraction\">extracting data</a>,\n",
    " <a href=\"/wiki/Website\" title=\"Website\">websites</a>,\n",
    " <a href=\"/wiki/World_Wide_Web\" title=\"World Wide Web\">World Wide Web</a>,\n",
    " <a href=\"/wiki/Hypertext_Transfer_Protocol\" title=\"Hypertext Transfer Protocol\">Hypertext Transfer Protocol</a>,\n",
    " <a href=\"/wiki/Internet_bot\" title=\"Internet bot\">bot</a>,\n",
    " <a href=\"/wiki/Web_crawler\" title=\"Web crawler\">web crawler</a>,\n",
    " <a href=\"/wiki/Database\" title=\"Database\">database</a>,\n",
    " <a href=\"/wiki/Data_retrieval\" title=\"Data retrieval\">retrieval</a>,\n",
    " <a href=\"/wiki/Data_analysis\" title=\"Data analysis\">analysis</a>,...]\n",
    " ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "problem": 15
   },
   "source": [
    "#### Problem 15 (3 pts)\n",
    "Remember, each `<a>` tag element contains an `href` attribute, which indicate's the hyperlink's destination. From the list you created in problem 14 create a new list of only the Wikipedia URLS. Keep only the `href` attributes that include the string \"/wiki/\" then append each of these to the end of the Wikipedia URL: \"https://en.wikipedia.org\". Print the resulting list of URLs.\n",
    "\n",
    "_**Confidence check:** The final list should have 68 elements and start with:_\n",
    "\n",
    "```\n",
    "['https://en.wikipedia.org/wiki/Data_scraping',\n",
    " 'https://en.wikipedia.org/wiki/Data_extraction',\n",
    " 'https://en.wikipedia.org/wiki/Website',\n",
    " 'https://en.wikipedia.org/wiki/World_Wide_Web',\n",
    " 'https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol',\n",
    " 'https://en.wikipedia.org/wiki/Internet_bot',\n",
    " 'https://en.wikipedia.org/wiki/Web_crawler',\n",
    " 'https://en.wikipedia.org/wiki/Database',\n",
    " 'https://en.wikipedia.org/wiki/Data_retrieval',\n",
    " 'https://en.wikipedia.org/wiki/Data_analysis',\n",
    " ...]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
